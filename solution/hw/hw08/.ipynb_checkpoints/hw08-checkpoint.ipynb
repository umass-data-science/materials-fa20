{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8: Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: Textbook chapter [14](https://umass-data-science.github.io/190fwebsite/textbook/14/why-the-mean-matters/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "Homework 8 is due **Monday, 11/19 at 11:59pm**. Start early so that you can come to office hours if you're stuck. Check the website for the office hours schedule. Late work will not be accepted as per the [policies](https://umass-data-science.github.io/190fwebsite/policy/) of this course. \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "For all problems that you must write our explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "! pip install -U okpy\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw08.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Bootstrap and The Normal Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will explore a dataset that includes the safety inspection scores for restauraunts in the city of Austin, Texas.  We will be interested in determining the average restaurant score (out of 100) for the city from a random sample of the scores.  We'll compare two methods for computing a confidence interval for that quantity: the bootstrap resampling method, and an approximation based on the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "pop_restaurants = Table.read_table('restaurant_inspection_scores.csv').drop(5,6)\n",
    "pop_restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 (Ungraded)\n",
    "Plot a histogram of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "pop_restaurants.hist('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = np.mean(pop_restaurants.column(3))\n",
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is impossible to find complete datasets like this.  Imagine we instead had access only to a random sample of 100 restaurant inspections, called `restaurant_sample`.  That table is created below. We are interested in using this sample to estimate the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_sample = pop_restaurants.sample(100, with_replacement=False)\n",
    "restaurant_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 (Ungraded)\n",
    "Plot a histogram of the **sample** scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here:\n",
    "restaurant_sample.hist('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the **sample mean**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Complete the function `bootstrap_scores` below. It should take no arguments. It should simulate drawing 5000 resamples from `restaurant_sample` and computing the mean restaurant score in each resample.  It should return an array of those 5000 resample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_scores():\n",
    "    resampled_means = make_array()\n",
    "    for i in range(5000):\n",
    "        resampled_mean = np.mean(restaurant_sample.sample().column(\"Score\"))\n",
    "        resampled_means = np.append(resampled_means, resampled_mean)\n",
    "    return resampled_means\n",
    "\n",
    "resampled_means = bootstrap_scores()\n",
    "resampled_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q1_3')\n",
    "\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the histogram of the **resampled means**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Resampled Means', resampled_means).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Compute a 95 percent confidence interval for the average restaurant score using the array `resampled_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "manual_problem_id": "bootstrap_4"
   },
   "outputs": [],
   "source": [
    "lower_bound = percentile(2.5, resampled_means)\n",
    "upper_bound = percentile(97.5, resampled_means)\n",
    "print(\"95% confidence interval for the average restaurant score, computed by bootstrapping:\\n(\",lower_bound, \",\", upper_bound, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Does the distribution of the resampled mean scores look normally distributed? State \"yes\" or \"no\" and describe in one sentence why you should expect this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "bootstrap_6"
   },
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "Does the distribution of the **sample scores** (notice we're no longer talking about the resampled means) look normally distributed? State \"yes\" or \"no\" and describe in one sentence why you should expect this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "bootstrap_5"
   },
   "source": [
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last question, you'll need to recall two facts.\n",
    "1. If a group of numbers has a normal distribution, around 95% of them lie within 2 standard deviations of their mean.\n",
    "2. The Central Limit Theorem tells us the quantitative relationship between\n",
    "    * the standard deviation of an array of numbers and\n",
    "    * the standard deviation of an array of means of samples taken from those numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Without referencing the array `resampled_means` or performing any new simulations, calculate an interval around the `sample_mean` that covers approximately 95% of the numbers in the `resampled_means` array.  **You may use the following values to compute your result, but you should not perform additional resampling** - think about how you can use the CLT to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "manual_problem_id": "bootstrap_7"
   },
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_sd = np.std(restaurant_sample.column(3))\n",
    "sample_size = restaurant_sample.num_rows\n",
    "\n",
    "lower_bound_normal = sample_mean - 1.96 * sample_sd / np.sqrt(sample_size)\n",
    "upper_bound_normal = sample_mean + 1.96 * sample_sd / np.sqrt(sample_size)\n",
    "print(\"95% confidence interval for the average restaurant score, computed by a normal approximation:\\n(\",lower_bound_normal, \",\", upper_bound_normal, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confidence interval should look very similar to the one you computed in Question 4. If not, try calculating the inner 95 percent using 1.96 standard deviations instead of 2 for a more precise calculation. If they are still very different, there may be an error in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing the Central Limit Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the **sum** or **average** of a large random sample drawn with replacement will be roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that the standard deviation of this normal distribution is given by \n",
    "\n",
    "$$\\frac{\\texttt{sd of the original distribution}}{\\sqrt{\\texttt{sample size}}}$$ \n",
    "\n",
    "In other words, suppose we start with *any distribution* that has standard deviation $x$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the **mean** of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{x}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but in this exercise, we will be exploring some data to see the CLT in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as sample size goes up.\n",
    "\n",
    "Consider a coin flip. If we say `Heads` is $1$ and `Tails` is $0$, then there's a 50% chance of getting a 1 and a 50% chance of getting a 0, which is definitely not a normal distribution.  The average of several coin tosses, where Heads is 1 and Tails is 0, is equal to the proportion of heads in those coin tosses, so the CLT should apply if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `simulate_sample_n` that takes in a sample size $n$. It should return an array that contains 5000 sample proportions of heads, each from $n$ coin flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size_n(n):\n",
    "    coin_proportions = make_array(.5, .5) # our coin is fair\n",
    "    heads_proportions = make_array()\n",
    "    for i in np.arange(5000):\n",
    "        simulated_proportions = sample_proportions(n, coin_proportions)\n",
    "        prop_heads = simulated_proportions[0]\n",
    "        heads_proportions = np.append(heads_proportions, prop_heads)\n",
    "    return heads_proportions\n",
    "\n",
    "sample_size_n(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for various sample sizes. Drag the slider or click on the number to the right to type in a sample size of your choice. The x- and y-scales are kept the same to facilitate comparisons. Notice the shape of the graph as the sample size increases and decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "from ipywidgets import interact\n",
    "\n",
    "def outer(f):\n",
    "    def graph(x):\n",
    "        bins = np.arange(-0.01,1.05,0.02)\n",
    "        sample_props = f(x)\n",
    "        Table().with_column('Sample Size: {}'.format(x), sample_props).hist(bins=bins)\n",
    "        plt.ylim(0, 30)\n",
    "        print('Sample SD:', np.std(sample_props))\n",
    "        plt.show()\n",
    "    return graph\n",
    "    \n",
    "interact(outer(sample_size_n), x=(0, 400, 1), continuous_update=False);\n",
    "\n",
    "# Min sample size is 0, max is 400\n",
    "# The graph will refresh a few times when you drag the slider around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even the means of samples of 10 items follow a roughly bell-shaped distribution.  A sample of 50 items looks quite bell-shaped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "clt_2"
   },
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 2:** In the plot for a sample size of 10, why are the bars spaced at intervals of .1, with gaps in between?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "clt_2"
   },
   "source": [
    "The distance between the bins creates the gaps between the bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "Now we will test the second claim of the CLT: That the SD of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "We have imported the flight delay data and computed its standard deviation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "united = Table.read_table('united_summer2015.csv')\n",
    "united_std = np.std(united.column('Delay'))\n",
    "united_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 3:** Write a function called `empirical_sample_mean_sd` that takes a sample size `n` as its argument. The function should simulate 500 samples with replacemnt of size `n` from the flight delays dataset, and it should return the standard deviation of the **means of those 500 samples**.\n",
    "\n",
    "*Hint:* This function will be similar to the `sample_size_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_sample_mean_sd(n):\n",
    "    sample_means = make_array()\n",
    "    for i in np.arange(500):\n",
    "        sample = united.sample(n).column('Delay')\n",
    "        sample_mean = np.mean(sample)\n",
    "        sample_means = np.append(sample_means, sample_mean)\n",
    "    return np.std(sample_means)\n",
    "\n",
    "empirical_sample_mean_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q2_3')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Now, write a function called `predict_sample_mean_sd` to find the predicted value of the standard deviation of means according to the relationship between the standard deviation of the sample mean and sample size that is discussed [here](https://umass-data-science.github.io/190fwebsite/textbook/14/5/variability-of-the-sample-mean/) in the textbook. It takes a sample size `n` (a number) as its argument.  It returns the predicted value of the standard deviation of the mean delay time for samples of size `n` from the flight delays (represented in the table `united`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample_mean_sd(n):\n",
    "    return united_std / np.sqrt(n)\n",
    "\n",
    "predict_sample_mean_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q2_4')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The cell below will plot the predicted and empirical SDs for the delay data for various sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sd_table = Table().with_column('Sample Size', np.arange(1,101))\n",
    "predicted = sd_table.apply(predict_sample_mean_sd, 'Sample Size')\n",
    "empirical = sd_table.apply(empirical_sample_mean_sd, 'Sample Size')\n",
    "sd_table = sd_table.with_columns('Predicted SD', predicted, 'Empirical SD', empirical)\n",
    "sd_table.scatter('Sample Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 5:** Do our predicted and empirical values match? Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "clt_5"
   },
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the `submit` cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to [okpy.org](https://okpy.org/) and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
